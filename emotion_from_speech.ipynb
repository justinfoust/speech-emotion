{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Emotion Recognition from Speech\n",
    "\n",
    "Using neural networks, audio data from actors were used to train a model to associate emotions with speech."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr></hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module, Functions, and Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa  #  Analyze audio files\n",
    "import soundfile  #  Read sound files\n",
    "import os, glob, joblib\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier  #  Multi-Layer Perceptron classifier (Artificial Neural Network)\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function used to cycle through audio files and extract features to use to train model\n",
    "\n",
    "def extract_feature(file_name):\n",
    "    with soundfile.SoundFile(file_name) as sf:\n",
    "        X = sf.read(dtype=\"float32\")\n",
    "        sample_rate = sf.samplerate\n",
    "        \n",
    "        result = np.array([])\n",
    "        \n",
    "# Mel-frequency cepstral coefficients - More accuratly represents human speech\n",
    "        mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T, axis=0)\n",
    "\n",
    "# Chromagram from a waveform - Returns normalized energy values for 12 distinct semitones\n",
    "        stft = np.abs(librosa.stft(X))\n",
    "        chroma = np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T,axis=0)\n",
    "          \n",
    "# Mel-scaled spectrogram - Frequency histogram based on percieved frequencies\n",
    "        mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
    "        \n",
    "    return np.hstack((mfccs, chroma, mel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary of emotions from dataset\n",
    "\n",
    "emotions = {\n",
    "  '01':'neutral',\n",
    "  '02':'calm',\n",
    "  '03':'happy',\n",
    "  '04':'sad',\n",
    "  '05':'angry',\n",
    "  '06':'fearful',\n",
    "  '07':'disgust',\n",
    "  '08':'surprised'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Pre-processing\n",
    "\n",
    "The audio files were obtained from the Ryerson Audio-Visiual Database of Emotional Speech and Song (RAVDESS), which consists of 24 actors saying the same short phrase in 8 different emotions.\n",
    "\n",
    "Data was acquired here:  https://zenodo.org/record/1188976/files/Audio_Speech_Actors_01-24.zip?download=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read through all audio files, extract features, and split into testing and training groups\n",
    "\n",
    "X,y = [], []\n",
    "\n",
    "for file in glob.glob(\"data/Actor_*/*.wav\"):\n",
    "    name = os.path.basename(file)\n",
    "# Emotions are indicated with a number in the file name corresponding to that defined in our dictionary.\n",
    "    emotion = emotions[name.split(\"-\")[2]]\n",
    "    feature = extract_feature(file)\n",
    "    \n",
    "    X.append(feature)\n",
    "    y.append(emotion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training data: 1076\n",
      "Number of testing data: 359\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(np.array(X), y, stratify=y, random_state=42)\n",
    "\n",
    "print(f'Number of training data: {X_train.shape[0]}\\nNumber of testing data: {X_test.shape[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize testing and training audio feature data\n",
    "\n",
    "X_scaler = MinMaxScaler().fit(X_train)\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classify emotions with number representation\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train)\n",
    "encoded_y_train = label_encoder.transform(y_train)\n",
    "encoded_y_test = label_encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_categorical = to_categorical(encoded_y_train)\n",
    "y_test_categorical = to_categorical(encoded_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data: (180, 8)\n"
     ]
    }
   ],
   "source": [
    "print(f'Shape of data: {X_train_scaled[0].shape[0], y_train_categorical[0].shape[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training\n",
    "\n",
    "Two methods were used to train a model to fit the data: a TensorFlow neural network; and a Scikit-Learn neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(units=300, activation='relu', input_dim=180))\n",
    "model.add(Dense(units=300, activation='relu'))\n",
    "model.add(Dense(units=300, activation='relu'))\n",
    "model.add(Dense(units=300, activation='relu'))\n",
    "model.add(Dense(units=300, activation='relu'))\n",
    "model.add(Dense(units=8, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 300)               54300     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 300)               90300     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 300)               90300     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 300)               90300     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 300)               90300     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 8)                 2408      \n",
      "=================================================================\n",
      "Total params: 417,908\n",
      "Trainable params: 417,908\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1076 samples\n",
      "Epoch 1/300\n",
      "1076/1076 [==============================] - 1s 529us/sample - loss: 1.9749 - accuracy: 0.2017\n",
      "Epoch 2/300\n",
      "1076/1076 [==============================] - 0s 116us/sample - loss: 1.7628 - accuracy: 0.2937\n",
      "Epoch 3/300\n",
      "1076/1076 [==============================] - 0s 114us/sample - loss: 1.6487 - accuracy: 0.3299\n",
      "Epoch 4/300\n",
      "1076/1076 [==============================] - 0s 117us/sample - loss: 1.5574 - accuracy: 0.3866\n",
      "Epoch 5/300\n",
      "1076/1076 [==============================] - 0s 113us/sample - loss: 1.5232 - accuracy: 0.4071\n",
      "Epoch 6/300\n",
      "1076/1076 [==============================] - 0s 117us/sample - loss: 1.4759 - accuracy: 0.4210\n",
      "Epoch 7/300\n",
      "1076/1076 [==============================] - 0s 190us/sample - loss: 1.3660 - accuracy: 0.4833\n",
      "Epoch 8/300\n",
      "1076/1076 [==============================] - 0s 118us/sample - loss: 1.3344 - accuracy: 0.4954\n",
      "Epoch 9/300\n",
      "1076/1076 [==============================] - 0s 115us/sample - loss: 1.2562 - accuracy: 0.5149\n",
      "Epoch 10/300\n",
      "1076/1076 [==============================] - 0s 123us/sample - loss: 1.1965 - accuracy: 0.5381\n",
      "Epoch 11/300\n",
      "1076/1076 [==============================] - 0s 125us/sample - loss: 1.2235 - accuracy: 0.5465\n",
      "Epoch 12/300\n",
      "1076/1076 [==============================] - 0s 118us/sample - loss: 1.1533 - accuracy: 0.5604\n",
      "Epoch 13/300\n",
      "1076/1076 [==============================] - 0s 118us/sample - loss: 1.0882 - accuracy: 0.6032\n",
      "Epoch 14/300\n",
      "1076/1076 [==============================] - 0s 117us/sample - loss: 1.0616 - accuracy: 0.5976\n",
      "Epoch 15/300\n",
      "1076/1076 [==============================] - 0s 119us/sample - loss: 1.0078 - accuracy: 0.6255\n",
      "Epoch 16/300\n",
      "1076/1076 [==============================] - 0s 120us/sample - loss: 0.9632 - accuracy: 0.6441\n",
      "Epoch 17/300\n",
      "1076/1076 [==============================] - 0s 120us/sample - loss: 0.9246 - accuracy: 0.6552\n",
      "Epoch 18/300\n",
      "1076/1076 [==============================] - 0s 118us/sample - loss: 0.8948 - accuracy: 0.6645\n",
      "Epoch 19/300\n",
      "1076/1076 [==============================] - 0s 113us/sample - loss: 0.8405 - accuracy: 0.6877\n",
      "Epoch 20/300\n",
      "1076/1076 [==============================] - 0s 116us/sample - loss: 0.9322 - accuracy: 0.6589\n",
      "Epoch 21/300\n",
      "1076/1076 [==============================] - 0s 114us/sample - loss: 0.8068 - accuracy: 0.7193\n",
      "Epoch 22/300\n",
      "1076/1076 [==============================] - 0s 118us/sample - loss: 0.8903 - accuracy: 0.6654\n",
      "Epoch 23/300\n",
      "1076/1076 [==============================] - 0s 116us/sample - loss: 0.7373 - accuracy: 0.7323\n",
      "Epoch 24/300\n",
      "1076/1076 [==============================] - 0s 115us/sample - loss: 0.7226 - accuracy: 0.7435\n",
      "Epoch 25/300\n",
      "1076/1076 [==============================] - 0s 120us/sample - loss: 0.7011 - accuracy: 0.7426\n",
      "Epoch 26/300\n",
      "1076/1076 [==============================] - 0s 121us/sample - loss: 0.6053 - accuracy: 0.7742\n",
      "Epoch 27/300\n",
      "1076/1076 [==============================] - 0s 119us/sample - loss: 0.7200 - accuracy: 0.7454\n",
      "Epoch 28/300\n",
      "1076/1076 [==============================] - 0s 114us/sample - loss: 0.6010 - accuracy: 0.7928\n",
      "Epoch 29/300\n",
      "1076/1076 [==============================] - 0s 115us/sample - loss: 0.5231 - accuracy: 0.8104\n",
      "Epoch 30/300\n",
      "1076/1076 [==============================] - 0s 118us/sample - loss: 0.5088 - accuracy: 0.8086\n",
      "Epoch 31/300\n",
      "1076/1076 [==============================] - 0s 116us/sample - loss: 0.4973 - accuracy: 0.8151\n",
      "Epoch 32/300\n",
      "1076/1076 [==============================] - 0s 114us/sample - loss: 0.5590 - accuracy: 0.7862\n",
      "Epoch 33/300\n",
      "1076/1076 [==============================] - 0s 119us/sample - loss: 0.4807 - accuracy: 0.8188\n",
      "Epoch 34/300\n",
      "1076/1076 [==============================] - 0s 117us/sample - loss: 0.6229 - accuracy: 0.7723\n",
      "Epoch 35/300\n",
      "1076/1076 [==============================] - 0s 122us/sample - loss: 0.5197 - accuracy: 0.7983\n",
      "Epoch 36/300\n",
      "1076/1076 [==============================] - 0s 123us/sample - loss: 0.4738 - accuracy: 0.8225\n",
      "Epoch 37/300\n",
      "1076/1076 [==============================] - 0s 119us/sample - loss: 0.5386 - accuracy: 0.8504\n",
      "Epoch 38/300\n",
      "1076/1076 [==============================] - 0s 119us/sample - loss: 0.4071 - accuracy: 0.8429\n",
      "Epoch 39/300\n",
      "1076/1076 [==============================] - 0s 123us/sample - loss: 0.4026 - accuracy: 0.8532\n",
      "Epoch 40/300\n",
      "1076/1076 [==============================] - 0s 126us/sample - loss: 0.4194 - accuracy: 0.8420 - loss: 0.4179 - accuracy: 0.84\n",
      "Epoch 41/300\n",
      "1076/1076 [==============================] - 0s 126us/sample - loss: 0.3810 - accuracy: 0.8522\n",
      "Epoch 42/300\n",
      "1076/1076 [==============================] - 0s 119us/sample - loss: 0.3027 - accuracy: 0.8903\n",
      "Epoch 43/300\n",
      "1076/1076 [==============================] - 0s 122us/sample - loss: 0.3830 - accuracy: 0.8625\n",
      "Epoch 44/300\n",
      "1076/1076 [==============================] - 0s 118us/sample - loss: 0.3842 - accuracy: 0.8634\n",
      "Epoch 45/300\n",
      "1076/1076 [==============================] - 0s 127us/sample - loss: 0.6132 - accuracy: 0.7862\n",
      "Epoch 46/300\n",
      "1076/1076 [==============================] - 0s 124us/sample - loss: 0.3485 - accuracy: 0.8727\n",
      "Epoch 47/300\n",
      "1076/1076 [==============================] - 0s 119us/sample - loss: 0.3027 - accuracy: 0.8894\n",
      "Epoch 48/300\n",
      "1076/1076 [==============================] - 0s 120us/sample - loss: 0.3564 - accuracy: 0.8680\n",
      "Epoch 49/300\n",
      "1076/1076 [==============================] - 0s 120us/sample - loss: 0.3136 - accuracy: 0.8931\n",
      "Epoch 50/300\n",
      "1076/1076 [==============================] - 0s 117us/sample - loss: 0.2508 - accuracy: 0.9089\n",
      "Epoch 51/300\n",
      "1076/1076 [==============================] - 0s 116us/sample - loss: 0.2277 - accuracy: 0.9229\n",
      "Epoch 52/300\n",
      "1076/1076 [==============================] - 0s 118us/sample - loss: 0.2071 - accuracy: 0.9303\n",
      "Epoch 53/300\n",
      "1076/1076 [==============================] - 0s 120us/sample - loss: 0.3194 - accuracy: 0.8792\n",
      "Epoch 54/300\n",
      "1076/1076 [==============================] - 0s 122us/sample - loss: 0.2359 - accuracy: 0.9164\n",
      "Epoch 55/300\n",
      "1076/1076 [==============================] - 0s 125us/sample - loss: 0.2295 - accuracy: 0.9191\n",
      "Epoch 56/300\n",
      "1076/1076 [==============================] - 0s 123us/sample - loss: 0.1787 - accuracy: 0.9414\n",
      "Epoch 57/300\n",
      "1076/1076 [==============================] - 0s 117us/sample - loss: 0.2267 - accuracy: 0.9247\n",
      "Epoch 58/300\n",
      "1076/1076 [==============================] - 0s 116us/sample - loss: 0.2440 - accuracy: 0.9136\n",
      "Epoch 59/300\n",
      "1076/1076 [==============================] - 0s 117us/sample - loss: 0.2100 - accuracy: 0.9247\n",
      "Epoch 60/300\n",
      "1076/1076 [==============================] - 0s 121us/sample - loss: 0.1717 - accuracy: 0.9480\n",
      "Epoch 61/300\n",
      "1076/1076 [==============================] - 0s 120us/sample - loss: 0.1076 - accuracy: 0.9693\n",
      "Epoch 62/300\n",
      "1076/1076 [==============================] - 0s 118us/sample - loss: 0.1007 - accuracy: 0.9684\n",
      "Epoch 63/300\n",
      "1076/1076 [==============================] - 0s 114us/sample - loss: 0.1507 - accuracy: 0.9545\n",
      "Epoch 64/300\n",
      "1076/1076 [==============================] - 0s 116us/sample - loss: 0.2506 - accuracy: 0.9071\n",
      "Epoch 65/300\n",
      "1076/1076 [==============================] - 0s 121us/sample - loss: 0.2492 - accuracy: 0.9173\n",
      "Epoch 66/300\n",
      "1076/1076 [==============================] - 0s 124us/sample - loss: 0.1805 - accuracy: 0.9322\n",
      "Epoch 67/300\n",
      "1076/1076 [==============================] - 0s 118us/sample - loss: 0.1612 - accuracy: 0.9442\n",
      "Epoch 68/300\n",
      "1076/1076 [==============================] - 0s 120us/sample - loss: 0.1511 - accuracy: 0.9480\n",
      "Epoch 69/300\n",
      "1076/1076 [==============================] - 0s 118us/sample - loss: 0.1300 - accuracy: 0.9572\n",
      "Epoch 70/300\n",
      "1076/1076 [==============================] - 0s 117us/sample - loss: 0.1227 - accuracy: 0.9582\n",
      "Epoch 71/300\n",
      "1076/1076 [==============================] - 0s 117us/sample - loss: 0.0889 - accuracy: 0.9749\n",
      "Epoch 72/300\n",
      "1076/1076 [==============================] - 0s 151us/sample - loss: 0.0920 - accuracy: 0.9684\n",
      "Epoch 73/300\n",
      "1076/1076 [==============================] - 0s 149us/sample - loss: 0.1453 - accuracy: 0.9489\n",
      "Epoch 74/300\n",
      "1076/1076 [==============================] - 0s 128us/sample - loss: 0.1167 - accuracy: 0.9545\n",
      "Epoch 75/300\n",
      "1076/1076 [==============================] - 0s 132us/sample - loss: 0.0515 - accuracy: 0.9842\n",
      "Epoch 76/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1076/1076 [==============================] - 0s 118us/sample - loss: 0.0837 - accuracy: 0.9758\n",
      "Epoch 77/300\n",
      "1076/1076 [==============================] - 0s 118us/sample - loss: 0.1264 - accuracy: 0.9600\n",
      "Epoch 78/300\n",
      "1076/1076 [==============================] - 0s 119us/sample - loss: 0.1353 - accuracy: 0.9489\n",
      "Epoch 79/300\n",
      "1076/1076 [==============================] - 0s 120us/sample - loss: 0.1938 - accuracy: 0.9322\n",
      "Epoch 80/300\n",
      "1076/1076 [==============================] - 0s 109us/sample - loss: 0.1232 - accuracy: 0.9545\n",
      "Epoch 81/300\n",
      "1076/1076 [==============================] - 0s 116us/sample - loss: 0.1192 - accuracy: 0.9591\n",
      "Epoch 82/300\n",
      "1076/1076 [==============================] - 0s 115us/sample - loss: 0.2298 - accuracy: 0.9182\n",
      "Epoch 83/300\n",
      "1076/1076 [==============================] - 0s 118us/sample - loss: 0.2177 - accuracy: 0.9219\n",
      "Epoch 84/300\n",
      "1076/1076 [==============================] - 0s 120us/sample - loss: 0.1461 - accuracy: 0.9442\n",
      "Epoch 85/300\n",
      "1076/1076 [==============================] - 0s 121us/sample - loss: 0.1149 - accuracy: 0.9628\n",
      "Epoch 86/300\n",
      "1076/1076 [==============================] - 0s 114us/sample - loss: 0.0654 - accuracy: 0.9814\n",
      "Epoch 87/300\n",
      "1076/1076 [==============================] - 0s 123us/sample - loss: 0.0696 - accuracy: 0.9777\n",
      "Epoch 88/300\n",
      "1076/1076 [==============================] - 0s 155us/sample - loss: 0.1414 - accuracy: 0.9526\n",
      "Epoch 89/300\n",
      "1076/1076 [==============================] - 0s 148us/sample - loss: 0.0849 - accuracy: 0.9749\n",
      "Epoch 90/300\n",
      "1076/1076 [==============================] - 0s 151us/sample - loss: 0.1522 - accuracy: 0.9470\n",
      "Epoch 91/300\n",
      "1076/1076 [==============================] - 0s 154us/sample - loss: 0.0940 - accuracy: 0.9656\n",
      "Epoch 92/300\n",
      "1076/1076 [==============================] - 0s 156us/sample - loss: 0.2151 - accuracy: 0.9433\n",
      "Epoch 93/300\n",
      "1076/1076 [==============================] - 0s 162us/sample - loss: 0.5223 - accuracy: 0.8383\n",
      "Epoch 94/300\n",
      "1076/1076 [==============================] - 0s 160us/sample - loss: 0.1114 - accuracy: 0.9712\n",
      "Epoch 95/300\n",
      "1076/1076 [==============================] - 0s 151us/sample - loss: 0.0639 - accuracy: 0.9786\n",
      "Epoch 96/300\n",
      "1076/1076 [==============================] - 0s 150us/sample - loss: 0.0296 - accuracy: 0.9916\n",
      "Epoch 97/300\n",
      "1076/1076 [==============================] - 0s 152us/sample - loss: 0.0170 - accuracy: 0.9981\n",
      "Epoch 98/300\n",
      "1076/1076 [==============================] - 0s 155us/sample - loss: 0.0154 - accuracy: 0.9963\n",
      "Epoch 99/300\n",
      "1076/1076 [==============================] - 0s 167us/sample - loss: 0.0071 - accuracy: 0.9991\n",
      "Epoch 100/300\n",
      "1076/1076 [==============================] - 0s 170us/sample - loss: 0.0059 - accuracy: 0.9991\n",
      "Epoch 101/300\n",
      "1076/1076 [==============================] - 0s 167us/sample - loss: 0.0052 - accuracy: 0.9991\n",
      "Epoch 102/300\n",
      "1076/1076 [==============================] - 0s 160us/sample - loss: 0.0107 - accuracy: 0.9954\n",
      "Epoch 103/300\n",
      "1076/1076 [==============================] - 0s 163us/sample - loss: 0.0157 - accuracy: 0.9963\n",
      "Epoch 104/300\n",
      "1076/1076 [==============================] - 0s 156us/sample - loss: 0.0101 - accuracy: 1.0000\n",
      "Epoch 105/300\n",
      "1076/1076 [==============================] - 0s 165us/sample - loss: 0.0518 - accuracy: 0.9833\n",
      "Epoch 106/300\n",
      "1076/1076 [==============================] - 0s 167us/sample - loss: 0.3792 - accuracy: 0.8829\n",
      "Epoch 107/300\n",
      "1076/1076 [==============================] - 0s 172us/sample - loss: 0.4191 - accuracy: 0.8699\n",
      "Epoch 108/300\n",
      "1076/1076 [==============================] - 0s 203us/sample - loss: 0.1094 - accuracy: 0.9675\n",
      "Epoch 109/300\n",
      "1076/1076 [==============================] - 0s 181us/sample - loss: 0.0504 - accuracy: 0.9842\n",
      "Epoch 110/300\n",
      "1076/1076 [==============================] - 0s 186us/sample - loss: 0.0577 - accuracy: 0.9786\n",
      "Epoch 111/300\n",
      "1076/1076 [==============================] - 0s 162us/sample - loss: 0.1505 - accuracy: 0.9498\n",
      "Epoch 112/300\n",
      "1076/1076 [==============================] - 0s 167us/sample - loss: 0.1591 - accuracy: 0.9461\n",
      "Epoch 113/300\n",
      "1076/1076 [==============================] - 0s 158us/sample - loss: 0.0653 - accuracy: 0.9814\n",
      "Epoch 114/300\n",
      "1076/1076 [==============================] - 0s 147us/sample - loss: 0.0359 - accuracy: 0.9907\n",
      "Epoch 115/300\n",
      "1076/1076 [==============================] - 0s 161us/sample - loss: 0.0470 - accuracy: 0.9833\n",
      "Epoch 116/300\n",
      "1076/1076 [==============================] - 0s 164us/sample - loss: 0.0394 - accuracy: 0.9861\n",
      "Epoch 117/300\n",
      "1076/1076 [==============================] - 0s 161us/sample - loss: 0.0541 - accuracy: 0.9861\n",
      "Epoch 118/300\n",
      "1076/1076 [==============================] - 0s 158us/sample - loss: 0.0495 - accuracy: 0.9851\n",
      "Epoch 119/300\n",
      "1076/1076 [==============================] - 0s 162us/sample - loss: 0.0724 - accuracy: 0.9786\n",
      "Epoch 120/300\n",
      "1076/1076 [==============================] - 0s 156us/sample - loss: 0.0622 - accuracy: 0.9740\n",
      "Epoch 121/300\n",
      "1076/1076 [==============================] - 0s 166us/sample - loss: 0.2385 - accuracy: 0.9275\n",
      "Epoch 122/300\n",
      "1076/1076 [==============================] - 0s 168us/sample - loss: 0.1946 - accuracy: 0.9368\n",
      "Epoch 123/300\n",
      "1076/1076 [==============================] - 0s 169us/sample - loss: 0.0664 - accuracy: 0.9796\n",
      "Epoch 124/300\n",
      "1076/1076 [==============================] - 0s 164us/sample - loss: 0.0127 - accuracy: 0.9981\n",
      "Epoch 125/300\n",
      "1076/1076 [==============================] - 0s 172us/sample - loss: 0.0049 - accuracy: 1.0000\n",
      "Epoch 126/300\n",
      "1076/1076 [==============================] - 0s 165us/sample - loss: 0.0031 - accuracy: 1.0000\n",
      "Epoch 127/300\n",
      "1076/1076 [==============================] - 0s 165us/sample - loss: 0.0051 - accuracy: 0.9991\n",
      "Epoch 128/300\n",
      "1076/1076 [==============================] - 0s 245us/sample - loss: 0.0042 - accuracy: 0.9991\n",
      "Epoch 129/300\n",
      "1076/1076 [==============================] - 0s 171us/sample - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 130/300\n",
      "1076/1076 [==============================] - 0s 160us/sample - loss: 8.9768e-04 - accuracy: 1.0000\n",
      "Epoch 131/300\n",
      "1076/1076 [==============================] - 0s 165us/sample - loss: 7.3914e-04 - accuracy: 1.0000\n",
      "Epoch 132/300\n",
      "1076/1076 [==============================] - 0s 166us/sample - loss: 6.5042e-04 - accuracy: 1.0000\n",
      "Epoch 133/300\n",
      "1076/1076 [==============================] - 0s 155us/sample - loss: 5.9353e-04 - accuracy: 1.0000\n",
      "Epoch 134/300\n",
      "1076/1076 [==============================] - 0s 152us/sample - loss: 5.4851e-04 - accuracy: 1.0000\n",
      "Epoch 135/300\n",
      "1076/1076 [==============================] - 0s 163us/sample - loss: 5.0536e-04 - accuracy: 1.0000\n",
      "Epoch 136/300\n",
      "1076/1076 [==============================] - 0s 148us/sample - loss: 4.7187e-04 - accuracy: 1.0000\n",
      "Epoch 137/300\n",
      "1076/1076 [==============================] - 0s 184us/sample - loss: 4.3044e-04 - accuracy: 1.0000\n",
      "Epoch 138/300\n",
      "1076/1076 [==============================] - 0s 190us/sample - loss: 4.0612e-04 - accuracy: 1.0000\n",
      "Epoch 139/300\n",
      "1076/1076 [==============================] - 0s 172us/sample - loss: 3.8762e-04 - accuracy: 1.0000\n",
      "Epoch 140/300\n",
      "1076/1076 [==============================] - 0s 172us/sample - loss: 3.6090e-04 - accuracy: 1.0000\n",
      "Epoch 141/300\n",
      "1076/1076 [==============================] - 0s 181us/sample - loss: 3.3831e-04 - accuracy: 1.0000\n",
      "Epoch 142/300\n",
      "1076/1076 [==============================] - 0s 162us/sample - loss: 3.1789e-04 - accuracy: 1.0000\n",
      "Epoch 143/300\n",
      "1076/1076 [==============================] - ETA: 0s - loss: 2.7093e-04 - accuracy: 1.00 - 0s 165us/sample - loss: 2.9857e-04 - accuracy: 1.0000\n",
      "Epoch 144/300\n",
      "1076/1076 [==============================] - 0s 166us/sample - loss: 2.8233e-04 - accuracy: 1.0000\n",
      "Epoch 145/300\n",
      "1076/1076 [==============================] - 0s 160us/sample - loss: 2.6984e-04 - accuracy: 1.0000\n",
      "Epoch 146/300\n",
      "1076/1076 [==============================] - 0s 166us/sample - loss: 2.5567e-04 - accuracy: 1.0000\n",
      "Epoch 147/300\n",
      "1076/1076 [==============================] - 0s 163us/sample - loss: 2.4524e-04 - accuracy: 1.0000\n",
      "Epoch 148/300\n",
      "1076/1076 [==============================] - 0s 148us/sample - loss: 2.3448e-04 - accuracy: 1.0000\n",
      "Epoch 149/300\n",
      "1076/1076 [==============================] - 0s 175us/sample - loss: 2.2113e-04 - accuracy: 1.0000\n",
      "Epoch 150/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1076/1076 [==============================] - 0s 179us/sample - loss: 2.1169e-04 - accuracy: 1.0000\n",
      "Epoch 151/300\n",
      "1076/1076 [==============================] - 0s 179us/sample - loss: 2.0211e-04 - accuracy: 1.0000\n",
      "Epoch 152/300\n",
      "1076/1076 [==============================] - 0s 146us/sample - loss: 1.9311e-04 - accuracy: 1.0000\n",
      "Epoch 153/300\n",
      "1076/1076 [==============================] - 0s 157us/sample - loss: 1.8449e-04 - accuracy: 1.0000\n",
      "Epoch 154/300\n",
      "1076/1076 [==============================] - 0s 164us/sample - loss: 1.7776e-04 - accuracy: 1.0000\n",
      "Epoch 155/300\n",
      "1076/1076 [==============================] - 0s 153us/sample - loss: 1.7328e-04 - accuracy: 1.0000\n",
      "Epoch 156/300\n",
      "1076/1076 [==============================] - 0s 146us/sample - loss: 1.6428e-04 - accuracy: 1.0000\n",
      "Epoch 157/300\n",
      "1076/1076 [==============================] - 0s 146us/sample - loss: 1.5724e-04 - accuracy: 1.0000\n",
      "Epoch 158/300\n",
      "1076/1076 [==============================] - 0s 146us/sample - loss: 1.5266e-04 - accuracy: 1.0000\n",
      "Epoch 159/300\n",
      "1076/1076 [==============================] - 0s 146us/sample - loss: 1.4629e-04 - accuracy: 1.0000\n",
      "Epoch 160/300\n",
      "1076/1076 [==============================] - 0s 145us/sample - loss: 1.4018e-04 - accuracy: 1.0000\n",
      "Epoch 161/300\n",
      "1076/1076 [==============================] - 0s 168us/sample - loss: 1.3523e-04 - accuracy: 1.0000\n",
      "Epoch 162/300\n",
      "1076/1076 [==============================] - 0s 168us/sample - loss: 1.3140e-04 - accuracy: 1.0000\n",
      "Epoch 163/300\n",
      "1076/1076 [==============================] - 0s 151us/sample - loss: 1.2629e-04 - accuracy: 1.0000\n",
      "Epoch 164/300\n",
      "1076/1076 [==============================] - 0s 154us/sample - loss: 1.2149e-04 - accuracy: 1.0000\n",
      "Epoch 165/300\n",
      "1076/1076 [==============================] - 0s 150us/sample - loss: 1.1732e-04 - accuracy: 1.0000\n",
      "Epoch 166/300\n",
      "1076/1076 [==============================] - 0s 154us/sample - loss: 1.1334e-04 - accuracy: 1.0000\n",
      "Epoch 167/300\n",
      "1076/1076 [==============================] - 0s 166us/sample - loss: 1.1037e-04 - accuracy: 1.0000\n",
      "Epoch 168/300\n",
      "1076/1076 [==============================] - 0s 154us/sample - loss: 1.0658e-04 - accuracy: 1.0000\n",
      "Epoch 169/300\n",
      "1076/1076 [==============================] - 0s 184us/sample - loss: 1.0270e-04 - accuracy: 1.0000\n",
      "Epoch 170/300\n",
      "1076/1076 [==============================] - 0s 172us/sample - loss: 9.9073e-05 - accuracy: 1.0000\n",
      "Epoch 171/300\n",
      "1076/1076 [==============================] - 0s 154us/sample - loss: 9.6397e-05 - accuracy: 1.0000\n",
      "Epoch 172/300\n",
      "1076/1076 [==============================] - 0s 149us/sample - loss: 9.3387e-05 - accuracy: 1.0000\n",
      "Epoch 173/300\n",
      "1076/1076 [==============================] - 0s 159us/sample - loss: 9.0213e-05 - accuracy: 1.0000\n",
      "Epoch 174/300\n",
      "1076/1076 [==============================] - 0s 161us/sample - loss: 8.7532e-05 - accuracy: 1.0000\n",
      "Epoch 175/300\n",
      "1076/1076 [==============================] - 0s 155us/sample - loss: 8.5595e-05 - accuracy: 1.0000\n",
      "Epoch 176/300\n",
      "1076/1076 [==============================] - 0s 163us/sample - loss: 8.2177e-05 - accuracy: 1.0000\n",
      "Epoch 177/300\n",
      "1076/1076 [==============================] - 0s 159us/sample - loss: 7.9774e-05 - accuracy: 1.0000\n",
      "Epoch 178/300\n",
      "1076/1076 [==============================] - 0s 167us/sample - loss: 7.7266e-05 - accuracy: 1.0000\n",
      "Epoch 179/300\n",
      "1076/1076 [==============================] - 0s 154us/sample - loss: 7.5719e-05 - accuracy: 1.0000\n",
      "Epoch 180/300\n",
      "1076/1076 [==============================] - 0s 146us/sample - loss: 7.2799e-05 - accuracy: 1.0000\n",
      "Epoch 181/300\n",
      "1076/1076 [==============================] - 0s 158us/sample - loss: 7.1194e-05 - accuracy: 1.0000\n",
      "Epoch 182/300\n",
      "1076/1076 [==============================] - 0s 169us/sample - loss: 6.8515e-05 - accuracy: 1.0000\n",
      "Epoch 183/300\n",
      "1076/1076 [==============================] - 0s 161us/sample - loss: 6.6969e-05 - accuracy: 1.0000\n",
      "Epoch 184/300\n",
      "1076/1076 [==============================] - 0s 163us/sample - loss: 6.4760e-05 - accuracy: 1.0000\n",
      "Epoch 185/300\n",
      "1076/1076 [==============================] - 0s 176us/sample - loss: 6.2926e-05 - accuracy: 1.0000\n",
      "Epoch 186/300\n",
      "1076/1076 [==============================] - 0s 169us/sample - loss: 6.1562e-05 - accuracy: 1.0000\n",
      "Epoch 187/300\n",
      "1076/1076 [==============================] - 0s 160us/sample - loss: 5.9634e-05 - accuracy: 1.0000\n",
      "Epoch 188/300\n",
      "1076/1076 [==============================] - 0s 166us/sample - loss: 5.7828e-05 - accuracy: 1.0000\n",
      "Epoch 189/300\n",
      "1076/1076 [==============================] - 0s 184us/sample - loss: 5.6470e-05 - accuracy: 1.0000 - loss: 4.8755e-05 - accuracy: 1.\n",
      "Epoch 190/300\n",
      "1076/1076 [==============================] - 0s 169us/sample - loss: 5.4877e-05 - accuracy: 1.0000\n",
      "Epoch 191/300\n",
      "1076/1076 [==============================] - 0s 157us/sample - loss: 5.3774e-05 - accuracy: 1.0000\n",
      "Epoch 192/300\n",
      "1076/1076 [==============================] - 0s 167us/sample - loss: 5.2254e-05 - accuracy: 1.0000\n",
      "Epoch 193/300\n",
      "1076/1076 [==============================] - 0s 210us/sample - loss: 5.1054e-05 - accuracy: 1.0000\n",
      "Epoch 194/300\n",
      "1076/1076 [==============================] - 0s 161us/sample - loss: 4.9527e-05 - accuracy: 1.0000\n",
      "Epoch 195/300\n",
      "1076/1076 [==============================] - 0s 160us/sample - loss: 4.7857e-05 - accuracy: 1.0000\n",
      "Epoch 196/300\n",
      "1076/1076 [==============================] - 0s 164us/sample - loss: 4.6822e-05 - accuracy: 1.0000\n",
      "Epoch 197/300\n",
      "1076/1076 [==============================] - 0s 149us/sample - loss: 4.5935e-05 - accuracy: 1.0000\n",
      "Epoch 198/300\n",
      "1076/1076 [==============================] - 0s 146us/sample - loss: 4.4573e-05 - accuracy: 1.0000\n",
      "Epoch 199/300\n",
      "1076/1076 [==============================] - 0s 154us/sample - loss: 4.3089e-05 - accuracy: 1.0000\n",
      "Epoch 200/300\n",
      "1076/1076 [==============================] - 0s 161us/sample - loss: 4.2105e-05 - accuracy: 1.0000\n",
      "Epoch 201/300\n",
      "1076/1076 [==============================] - 0s 185us/sample - loss: 4.1090e-05 - accuracy: 1.0000\n",
      "Epoch 202/300\n",
      "1076/1076 [==============================] - 0s 178us/sample - loss: 4.0697e-05 - accuracy: 1.0000\n",
      "Epoch 203/300\n",
      "1076/1076 [==============================] - 0s 171us/sample - loss: 3.8947e-05 - accuracy: 1.0000\n",
      "Epoch 204/300\n",
      "1076/1076 [==============================] - 0s 180us/sample - loss: 3.7986e-05 - accuracy: 1.0000\n",
      "Epoch 205/300\n",
      "1076/1076 [==============================] - 0s 163us/sample - loss: 3.7167e-05 - accuracy: 1.0000\n",
      "Epoch 206/300\n",
      "1076/1076 [==============================] - 0s 161us/sample - loss: 3.6294e-05 - accuracy: 1.0000\n",
      "Epoch 207/300\n",
      "1076/1076 [==============================] - 0s 152us/sample - loss: 3.5469e-05 - accuracy: 1.0000\n",
      "Epoch 208/300\n",
      "1076/1076 [==============================] - 0s 164us/sample - loss: 3.4548e-05 - accuracy: 1.0000\n",
      "Epoch 209/300\n",
      "1076/1076 [==============================] - 0s 159us/sample - loss: 3.3483e-05 - accuracy: 1.0000\n",
      "Epoch 210/300\n",
      "1076/1076 [==============================] - 0s 147us/sample - loss: 3.2832e-05 - accuracy: 1.0000\n",
      "Epoch 211/300\n",
      "1076/1076 [==============================] - 0s 253us/sample - loss: 3.1872e-05 - accuracy: 1.0000\n",
      "Epoch 212/300\n",
      "1076/1076 [==============================] - 0s 151us/sample - loss: 3.1167e-05 - accuracy: 1.0000\n",
      "Epoch 213/300\n",
      "1076/1076 [==============================] - 0s 149us/sample - loss: 3.0343e-05 - accuracy: 1.0000\n",
      "Epoch 214/300\n",
      "1076/1076 [==============================] - 0s 149us/sample - loss: 2.9621e-05 - accuracy: 1.0000\n",
      "Epoch 215/300\n",
      "1076/1076 [==============================] - 0s 163us/sample - loss: 2.8958e-05 - accuracy: 1.0000\n",
      "Epoch 216/300\n",
      "1076/1076 [==============================] - 0s 180us/sample - loss: 2.8322e-05 - accuracy: 1.0000 - loss: 2.8264e-05 - accuracy: 1.00\n",
      "Epoch 217/300\n",
      "1076/1076 [==============================] - 0s 158us/sample - loss: 2.7421e-05 - accuracy: 1.0000\n",
      "Epoch 218/300\n",
      "1076/1076 [==============================] - 0s 155us/sample - loss: 2.7044e-05 - accuracy: 1.0000\n",
      "Epoch 219/300\n",
      "1076/1076 [==============================] - 0s 154us/sample - loss: 2.6304e-05 - accuracy: 1.0000\n",
      "Epoch 220/300\n",
      "1076/1076 [==============================] - 0s 151us/sample - loss: 2.5711e-05 - accuracy: 1.0000\n",
      "Epoch 221/300\n",
      "1076/1076 [==============================] - 0s 149us/sample - loss: 2.4966e-05 - accuracy: 1.0000\n",
      "Epoch 222/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1076/1076 [==============================] - 0s 190us/sample - loss: 2.4404e-05 - accuracy: 1.0000 - loss: 2.0654e-05 - accuracy: 1.\n",
      "Epoch 223/300\n",
      "1076/1076 [==============================] - 0s 168us/sample - loss: 2.3949e-05 - accuracy: 1.0000\n",
      "Epoch 224/300\n",
      "1076/1076 [==============================] - 0s 174us/sample - loss: 2.3319e-05 - accuracy: 1.0000\n",
      "Epoch 225/300\n",
      "1076/1076 [==============================] - 0s 155us/sample - loss: 2.2789e-05 - accuracy: 1.0000\n",
      "Epoch 226/300\n",
      "1076/1076 [==============================] - 0s 163us/sample - loss: 2.2189e-05 - accuracy: 1.0000\n",
      "Epoch 227/300\n",
      "1076/1076 [==============================] - 0s 150us/sample - loss: 2.1624e-05 - accuracy: 1.0000\n",
      "Epoch 228/300\n",
      "1076/1076 [==============================] - 0s 151us/sample - loss: 2.1120e-05 - accuracy: 1.0000\n",
      "Epoch 229/300\n",
      "1076/1076 [==============================] - 0s 159us/sample - loss: 2.0849e-05 - accuracy: 1.0000\n",
      "Epoch 230/300\n",
      "1076/1076 [==============================] - 0s 160us/sample - loss: 2.0363e-05 - accuracy: 1.0000\n",
      "Epoch 231/300\n",
      "1076/1076 [==============================] - 0s 166us/sample - loss: 1.9852e-05 - accuracy: 1.0000\n",
      "Epoch 232/300\n",
      "1076/1076 [==============================] - 0s 156us/sample - loss: 1.9293e-05 - accuracy: 1.0000\n",
      "Epoch 233/300\n",
      "1076/1076 [==============================] - 0s 147us/sample - loss: 1.8744e-05 - accuracy: 1.0000\n",
      "Epoch 234/300\n",
      "1076/1076 [==============================] - 0s 150us/sample - loss: 1.8572e-05 - accuracy: 1.0000\n",
      "Epoch 235/300\n",
      "1076/1076 [==============================] - 0s 154us/sample - loss: 1.7870e-05 - accuracy: 1.0000\n",
      "Epoch 236/300\n",
      "1076/1076 [==============================] - 0s 167us/sample - loss: 1.7561e-05 - accuracy: 1.0000\n",
      "Epoch 237/300\n",
      "1076/1076 [==============================] - 0s 152us/sample - loss: 1.7196e-05 - accuracy: 1.0000\n",
      "Epoch 238/300\n",
      "1076/1076 [==============================] - 0s 161us/sample - loss: 1.6899e-05 - accuracy: 1.0000\n",
      "Epoch 239/300\n",
      "1076/1076 [==============================] - 0s 205us/sample - loss: 1.6357e-05 - accuracy: 1.0000\n",
      "Epoch 240/300\n",
      "1076/1076 [==============================] - 0s 162us/sample - loss: 1.6042e-05 - accuracy: 1.0000\n",
      "Epoch 241/300\n",
      "1076/1076 [==============================] - 0s 157us/sample - loss: 1.5713e-05 - accuracy: 1.0000\n",
      "Epoch 242/300\n",
      "1076/1076 [==============================] - 0s 155us/sample - loss: 1.5233e-05 - accuracy: 1.0000\n",
      "Epoch 243/300\n",
      "1076/1076 [==============================] - 0s 161us/sample - loss: 1.4952e-05 - accuracy: 1.0000\n",
      "Epoch 244/300\n",
      "1076/1076 [==============================] - 0s 153us/sample - loss: 1.4652e-05 - accuracy: 1.0000\n",
      "Epoch 245/300\n",
      "1076/1076 [==============================] - 0s 149us/sample - loss: 1.4286e-05 - accuracy: 1.0000\n",
      "Epoch 246/300\n",
      "1076/1076 [==============================] - 0s 157us/sample - loss: 1.3953e-05 - accuracy: 1.0000\n",
      "Epoch 247/300\n",
      "1076/1076 [==============================] - 0s 164us/sample - loss: 1.3739e-05 - accuracy: 1.0000\n",
      "Epoch 248/300\n",
      "1076/1076 [==============================] - 0s 152us/sample - loss: 1.3337e-05 - accuracy: 1.0000\n",
      "Epoch 249/300\n",
      "1076/1076 [==============================] - 0s 146us/sample - loss: 1.3075e-05 - accuracy: 1.0000\n",
      "Epoch 250/300\n",
      "1076/1076 [==============================] - 0s 147us/sample - loss: 1.2775e-05 - accuracy: 1.0000\n",
      "Epoch 251/300\n",
      "1076/1076 [==============================] - 0s 148us/sample - loss: 1.2467e-05 - accuracy: 1.0000\n",
      "Epoch 252/300\n",
      "1076/1076 [==============================] - 0s 151us/sample - loss: 1.2208e-05 - accuracy: 1.0000\n",
      "Epoch 253/300\n",
      "1076/1076 [==============================] - 0s 149us/sample - loss: 1.1903e-05 - accuracy: 1.0000\n",
      "Epoch 254/300\n",
      "1076/1076 [==============================] - 0s 176us/sample - loss: 1.1651e-05 - accuracy: 1.0000\n",
      "Epoch 255/300\n",
      "1076/1076 [==============================] - 0s 165us/sample - loss: 1.1521e-05 - accuracy: 1.0000\n",
      "Epoch 256/300\n",
      "1076/1076 [==============================] - 0s 167us/sample - loss: 1.1134e-05 - accuracy: 1.0000\n",
      "Epoch 257/300\n",
      "1076/1076 [==============================] - 0s 167us/sample - loss: 1.0944e-05 - accuracy: 1.0000\n",
      "Epoch 258/300\n",
      "1076/1076 [==============================] - 0s 156us/sample - loss: 1.0705e-05 - accuracy: 1.0000\n",
      "Epoch 259/300\n",
      "1076/1076 [==============================] - 0s 156us/sample - loss: 1.0470e-05 - accuracy: 1.0000\n",
      "Epoch 260/300\n",
      "1076/1076 [==============================] - 0s 150us/sample - loss: 1.0264e-05 - accuracy: 1.0000\n",
      "Epoch 261/300\n",
      "1076/1076 [==============================] - 0s 148us/sample - loss: 9.9286e-06 - accuracy: 1.0000\n",
      "Epoch 262/300\n",
      "1076/1076 [==============================] - 0s 168us/sample - loss: 9.7640e-06 - accuracy: 1.0000\n",
      "Epoch 263/300\n",
      "1076/1076 [==============================] - 0s 171us/sample - loss: 9.5432e-06 - accuracy: 1.0000\n",
      "Epoch 264/300\n",
      "1076/1076 [==============================] - 0s 153us/sample - loss: 9.3143e-06 - accuracy: 1.0000\n",
      "Epoch 265/300\n",
      "1076/1076 [==============================] - 0s 151us/sample - loss: 9.0792e-06 - accuracy: 1.0000\n",
      "Epoch 266/300\n",
      "1076/1076 [==============================] - 0s 147us/sample - loss: 8.8910e-06 - accuracy: 1.0000\n",
      "Epoch 267/300\n",
      "1076/1076 [==============================] - 0s 146us/sample - loss: 8.6996e-06 - accuracy: 1.0000\n",
      "Epoch 268/300\n",
      "1076/1076 [==============================] - 0s 154us/sample - loss: 8.4840e-06 - accuracy: 1.0000\n",
      "Epoch 269/300\n",
      "1076/1076 [==============================] - 0s 156us/sample - loss: 8.3264e-06 - accuracy: 1.0000\n",
      "Epoch 270/300\n",
      "1076/1076 [==============================] - 0s 162us/sample - loss: 8.1444e-06 - accuracy: 1.0000\n",
      "Epoch 271/300\n",
      "1076/1076 [==============================] - 0s 163us/sample - loss: 7.9566e-06 - accuracy: 1.0000\n",
      "Epoch 272/300\n",
      "1076/1076 [==============================] - 0s 157us/sample - loss: 7.8254e-06 - accuracy: 1.0000\n",
      "Epoch 273/300\n",
      "1076/1076 [==============================] - 0s 148us/sample - loss: 7.5921e-06 - accuracy: 1.0000\n",
      "Epoch 274/300\n",
      "1076/1076 [==============================] - 0s 148us/sample - loss: 7.4628e-06 - accuracy: 1.0000\n",
      "Epoch 275/300\n",
      "1076/1076 [==============================] - 0s 148us/sample - loss: 7.2361e-06 - accuracy: 1.0000\n",
      "Epoch 276/300\n",
      "1076/1076 [==============================] - 0s 150us/sample - loss: 7.0977e-06 - accuracy: 1.0000\n",
      "Epoch 277/300\n",
      "1076/1076 [==============================] - 0s 146us/sample - loss: 6.9438e-06 - accuracy: 1.0000\n",
      "Epoch 278/300\n",
      "1076/1076 [==============================] - 0s 154us/sample - loss: 6.7688e-06 - accuracy: 1.0000\n",
      "Epoch 279/300\n",
      "1076/1076 [==============================] - 0s 170us/sample - loss: 6.6259e-06 - accuracy: 1.0000\n",
      "Epoch 280/300\n",
      "1076/1076 [==============================] - 0s 185us/sample - loss: 6.5104e-06 - accuracy: 1.0000\n",
      "Epoch 281/300\n",
      "1076/1076 [==============================] - 0s 152us/sample - loss: 6.3080e-06 - accuracy: 1.0000\n",
      "Epoch 282/300\n",
      "1076/1076 [==============================] - 0s 153us/sample - loss: 6.2425e-06 - accuracy: 1.0000\n",
      "Epoch 283/300\n",
      "1076/1076 [==============================] - 0s 152us/sample - loss: 6.1168e-06 - accuracy: 1.0000\n",
      "Epoch 284/300\n",
      "1076/1076 [==============================] - 0s 164us/sample - loss: 6.0271e-06 - accuracy: 1.0000\n",
      "Epoch 285/300\n",
      "1076/1076 [==============================] - 0s 159us/sample - loss: 5.8324e-06 - accuracy: 1.0000\n",
      "Epoch 286/300\n",
      "1076/1076 [==============================] - 0s 184us/sample - loss: 5.7121e-06 - accuracy: 1.0000\n",
      "Epoch 287/300\n",
      "1076/1076 [==============================] - 0s 182us/sample - loss: 5.5471e-06 - accuracy: 1.0000\n",
      "Epoch 288/300\n",
      "1076/1076 [==============================] - 0s 168us/sample - loss: 5.4694e-06 - accuracy: 1.0000\n",
      "Epoch 289/300\n",
      "1076/1076 [==============================] - 0s 153us/sample - loss: 5.3654e-06 - accuracy: 1.0000 - loss: 5.7844e-06 - accuracy: 1.00\n",
      "Epoch 290/300\n",
      "1076/1076 [==============================] - 0s 161us/sample - loss: 5.2752e-06 - accuracy: 1.0000\n",
      "Epoch 291/300\n",
      "1076/1076 [==============================] - 0s 151us/sample - loss: 5.1365e-06 - accuracy: 1.0000\n",
      "Epoch 292/300\n",
      "1076/1076 [==============================] - 0s 150us/sample - loss: 4.9885e-06 - accuracy: 1.0000\n",
      "Epoch 293/300\n",
      "1076/1076 [==============================] - 0s 157us/sample - loss: 4.8827e-06 - accuracy: 1.0000\n",
      "Epoch 294/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1076/1076 [==============================] - 0s 176us/sample - loss: 4.8056e-06 - accuracy: 1.0000\n",
      "Epoch 295/300\n",
      "1076/1076 [==============================] - 0s 171us/sample - loss: 4.6878e-06 - accuracy: 1.0000\n",
      "Epoch 296/300\n",
      "1076/1076 [==============================] - 0s 150us/sample - loss: 4.5672e-06 - accuracy: 1.0000\n",
      "Epoch 297/300\n",
      "1076/1076 [==============================] - 0s 155us/sample - loss: 4.5640e-06 - accuracy: 1.0000\n",
      "Epoch 298/300\n",
      "1076/1076 [==============================] - 0s 151us/sample - loss: 4.3931e-06 - accuracy: 1.0000\n",
      "Epoch 299/300\n",
      "1076/1076 [==============================] - 0s 150us/sample - loss: 4.3101e-06 - accuracy: 1.0000\n",
      "Epoch 300/300\n",
      "1076/1076 [==============================] - 0s 146us/sample - loss: 4.2360e-06 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x162ac325f48>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train_scaled,\n",
    "    y_train_categorical,\n",
    "    epochs=300,\n",
    "    shuffle=True,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "359/359 - 0s - loss: 3.1276 - accuracy: 0.6908\n",
      "TensorFlow Results - Loss: 3.1276437306470526, Accuracy: 0.6908078193664551\n"
     ]
    }
   ],
   "source": [
    "# Test accuracy of model\n",
    "model_loss, model_accuracy = model.evaluate(X_test_scaled, y_test_categorical, verbose=2)\n",
    "\n",
    "print(f\"TensorFlow Results - Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "model.save(\"tf_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlpModel = MLPClassifier(\n",
    "    alpha = 0.01,\n",
    "    batch_size = 256,\n",
    "    epsilon = 1e-08,\n",
    "    hidden_layer_sizes = (300,),\n",
    "    learning_rate = 'adaptive',\n",
    "    max_iter = 1000,\n",
    "    #shuffle = False,\n",
    "    #n_iter_no_change = 20,\n",
    "    #learning_rate_init = 0.0001,\n",
    "    #beta_1 = 0.1,\n",
    "    #beta_2 = 0.9,\n",
    "    warm_start = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.01, batch_size=256, beta_1=0.9,\n",
       "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "              hidden_layer_sizes=(300,), learning_rate='adaptive',\n",
       "              learning_rate_init=0.001, max_iter=1000, momentum=0.9,\n",
       "              n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "              random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
       "              validation_fraction=0.1, verbose=False, warm_start=True)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlpModel.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP Results - Accuracy: 0.4986072423398329\n"
     ]
    }
   ],
   "source": [
    "# Test accuracy of model\n",
    "y_pred = mlpModel.predict(X_test)\n",
    "\n",
    "print(f'MLP Results - Accuracy: {accuracy_score(y_true=y_test, y_pred=y_pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mlp_model.sav']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save model\n",
    "joblib.dump(mlpModel, \"mlp_model.sav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
